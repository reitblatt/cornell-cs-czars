<head>

<title> PhD Professional Seminar -- 11 February 1997 -- Charles Van Loan </title>

</head>

<body bgcolor="#FFFFFF" Text="#000000">

<h2 align=center> Degrading Grading </h2>
<h4 align=center> Ph.D. Professional Seminar. 11 February 1997. </h4>
<h4 align=center> Charles Van Loan </h4>

<hr>
Main message:

<p>
Grading is inherently subjective. Professors are required to
pass judgement on students' work. In judging, it is necessary
to encorporate fairness.

<hr> 
Axioms of grading:
<ul>
<li> Grading should be fair and subjective. It is key to realize
that grading is often (always?) subjective. This is not a problem so
long as one works to keep grading fair as well. Grading "by formula",
while seemingly more fair, is not necessarily the best option.
More on this later.

<li> Grading should help realize course goals.

<li> Grading should help realize Department/University goals. One
should not be a slave to these goals, but one should be responsive
to them.
</ul>

<hr>
Final grades depend on more than a simple weighting of students'
component grades. One should probably take into account:
<ul>
<li> The student's score on each graded object.
<li> A "regrade" factor for each student on each graded object; 
regrades can be based on a number of different inputs which will
be discuss later.
<li> A weight assigned to each graded object indicating its influence
on the final grade.
<li> A "teacher's pet" factor (note that this can have negative
values).
</ul>

<hr>
Reporting Exam Grades:

<p>
While it is advisable to present a histogram of scores which
includes the corresponding letter grades for score ranges, allow
the boundaries between grade categories to be ambiguous on your
graph. This discourages students from fighting for an extra point
to move up a grade category.

<p>
Reporting grades in a linear list by student ID is the wrong way
to present the data. One wants to indicate what a score corresponds
to along an excellent to poor ranking.

<hr>
Report Problem Averages for Exams:

<p>
In addition to reporting the average score for the entire exam,
report the average score for each problem on the exam. This
indicates which problems were the hard problems and which were
straightforward. This helps the student evaluate their performance
and also lets the professor spot topics that he or she may have
taught poorly.

<p>
This information can also be used to spot students who have had
a flash of "brilliance" on the exam. One may want to reward these
students with extra discretionary points.

<hr>
Median Fixing for Exams:

<p>
If an exam has an abnormally low median students may face morale
problems from getting low scores even though comparatively their
performance is fine. It is best to avoid this situation. One way
to do this is to first look through the exams and figure out for
each problem whether the students tended to find it difficult or
easy. Grade the easiest problems first and then progress on to
the harder problems. If it appears that the median is going to
be too low, give more partial credit for the harder problems.

<p>
Another option that Dexter Kozen suggests is to not assign any
grades until all of the problems have been graded. Instead, keep
notes on what errors have been made and assign scores on a second
pass, giving partial credit to the degree that problem seems to
merit. This method tries to ensure that assignments are graded
consistently between students.

<p>
To avoid low medians when writing an exam, make about 50% of the
problems so straightforward that most students will be able to
do them. Because half of the test is on material that all
students should be required to know in order to pass the class,
this also provides a justification for failing students with a
grade below a certain level.

<hr>
Multiple Choice Questions:

<ul>
<li> Multiple choice questions are convenient and simplify grading.
<li> Multiple choice questions give the impression that the "answer
space" is discrete.
<li> Multiple choice questions are degrading and have no place in
a research university.
</ul>

Conclusion: Multiple choice questions are evil; <b>never</b> use them.

<p>
Instead of using multiple choice (or true/false) questions,
rewrite the questions so that the students can give written
answers. Besides admitting that there may be multiple answers
to any given question and that different students may interpret
the same question differently, this also allows the professor
to grade the question even if it turns out there was a flaw
in it.

<hr>
Weighting Problems on Homeworks:

<p>
Though students spend most of their time in a course doing
homework, that does not necessarily mean that most of the
points in their grade should come from the homework. By having
the homework questions count for a lower percentage of the
students' final grades, one can achieve a lower incidence of
cheating in the class.

<p>
When grading homeworks, use a coarse grained grading scheme.
Instead of grading a problem on a scale of 0 to 10, grade it
on a scale of 0 to 3, where each score is assigned the following
meanings:

<DL COMPACT>
<DT>0
<DD>Not attempted
<DT>1
<DD>Germ of a solution
<DT>2
<DD>Missed a minor point
<DT>3
<DD>Got it
</DL>

<p>
Better yet, one can use a binary grading scheme where questions
receive 0 points for no attempt and 1 point for any attempt. In this
case, the grade is being used as an incentive for students to at
least try the problem.

<p>
With either of these schemes, one should then tightly couple the
exam questions with the homework questions. In effect, the points
that students are not getting on their homework are being given
back to them on the exam. The time that students have spent doing
homework now "pays off".

<hr>
Interactive Grading:

<p>
Do not spend too much time grading any one student's solution to
a problem. If a student gives a solution that is convoluted, grade
hard and then note on the paper that they can come see you to explain
their solution. This puts the burden of figuring out a complex
solution on the student and makes for more efficient use of the
professor's time.

<hr>
Weighting Inputs to Final Course Grades:

<p>
Key principle:  <b>Subjective + Fair = Objective</b>

<p>
Given a set of homeworks, prelims, projects and a final exam, how
should the students' scores on each one factor into their final
grades?

<p>
Step one is to assign each graded object a percentage of the
final grade. As discussed before, it is recommended to make
homeworks a small percentage of the final grade as this helps
to ensure academic integrity. This is the "subjective" part
of the equation; percentages cannot totally measure a student's
performance.

<p>
Step two is to adjust these grades so that they are "fair". This
requires looking at each student's grades individually and
evaluating their performance. If a student has done exceptionally
well on one exam, one might reward that by raising their grade
a half mark. One can also take improvement on the part of the
student into account.

<p>
Adjusting grades for fairness is improved if a student's scores
on each problem of each homework and exam are recorded along the
way. This means that one can check if a student who got a
problem wrong on the homework learned and got it correct on the
exam or not. The grading process is more fine tuned. In a large
class where this might not be possible, students who are in trouble
can be asked to bring their past exams and/or homeworks to the
final so that this evaluation can be done on the subset of
students who are in risk of failing.

<p>
Note that by letting these "fairness" criteria factor into final
grades, a student with a lower numerical grade might get a higher
mark than another student with a slightly higher numerical mark.

<hr>
Reporting Course Grades:

<p>
As with reporting exam grades, reporting course grades should
not be done by a list posted by student ID or some other
identifier because it promotes competition between students to
no end. If a histogram is used, sharp cutoffs between grades
must be avoided as discussed above. However, because the
"fairness" factor can result in shifts in grades that the
professor might not wish to explain, or which could not be
shown on a histogram (such as grade ordering not matching score
ordering of students), a histogram of the scores might not
be acceptable.

<p>
Solution: Creative Underreporting

<p>
When reporting grades, show the histogram generated from the
flat scores in Step One of computing the final grades. Comment
at the bottom of the histogram that individual grades may be
shifted up under the course's previously described criteria
(e.g., improvement over time). Do not show students the
histogram that results from adding in the "fairness" factor.

<p>
One might also chose not to publically report the course grades.
While this is probably okay, it does not give the students any
context in which to evaluate themselves. Also, if the students
have received grade distribution information during the rest
of the class (and this is a vital method of feedback),
withholding this information at the end of the class may make
the grading system seem inconsistent.

<hr>
Interpreting Grades:

<p>
The announced meaning of letter grades:

<DL COMPACT>
<DT>A
<DD>Excellent
<DT>B
<DD>Very Good
<DT>C
<DD>Satisfactory
<DT>D
<DD>Poor
<DT>F
<DD>Unsatisfactory
</DL>

<p>
is not the same as the meaning that admissions offices or
employers assume that letter grades have in undergraduate
classes, namely:

<DL COMPACT>
<DT>A+
<DD>Excellent
<DT>A-
<DD>Very Good
<DT>B
<DD>Satisfactory
<DT>C
<DD>Poor
</DL>

<p>
The higher the level of a course, the more of an upwards
shift the grading curve has. In a typical grad course, the
meaning of letter grades might be taken as:

<DL COMPACT>
<DT>A+
<DD>Excellent
<DT>A
<DD>Very Good
<DT>A-
<DD>Good
<DT>B
<DD>Satisfactory
</DL>

<p>
The way that one's grades will be interpreted by others must,
to some extent, be taken into account when assigning grades.
However, there is always variation in the meaning of grades
across professors, departments, and time. This makes grading
with incredible precision a somewhat useless pursuit; the
"subjective + fair" model might give the best results given
the overall grading environment.

<hr>
Grade Point Averages:

<p>
Ideally, the quality of a student's transcript is a function
both of their GPA and of their course choices. However, some
employers or interviewers have GPA cutoffs so GPAs cannot be
ignored. Grade inflation both aggravates this problem and
makes it difficult to tell what a given grade means. To solve
this, some schools report the average grade for a class along
with the student's grade in the class on transcripts.

<p>
The S/U option has advantages and disadvantages for students. On
the positive side, a student may be more likely to take a class
which would be a stretch for them rather than avoiding the class
to preserve their GPA. However, grades act as an incentive for
students to do course work. Taking a class S/U lessens these
pressures and the student may not learn as much as he or she
could.

<hr>
Miscellaneous Comments:

<p>
Allowing team work on homeworks or projects can increase overall
academic integrity in a class. However, the issue then arises
of how to fairly grade team projects. How do you separate the
grades of individuals on the same team? Do you?

<p>
When assigning letter grades, how should +'s and -'s be used?
One can split all of the B students so that 1/3 receive a B+,
1/3 receive a B and 1/3 receive a B-. But it might be better to
assign mostly B's and use +'s and -'s sparingly, mostly to indicate
the effects of the "fairness" factor.

<p>
The previous condemnation of multiple choice questions on exams
also holds for multiple choice questions on course evaluations.
The statistics generated are most likely meaningless. With 
university-wide forms, the questions asked are sometimes irrelevant
for the class. If possible, try to get a written evaluation of
the class.

<p>
There may be internal criteria for "good standing" at the
university or required grade levels for financial support.
These grade levels are often inconsistent with the "C is
satisfactory" interpretation of grades. As professors respond
to these pressures they contribute to grade inflation. However,
these high required levels are reasonable to some extent.
By requiring a "B-" average, a student is not penalized for a
single poor performance but rather for overall poor
performance. Also, by having a slightly high grade criterion
for "good standing" a university is able to detect potential
problems while the the student can still be helped.

<hr>
<A HREF=http://www.cs.cornell.edu/Info/Courses/Spring-97/CS706/> Back </A>
to Ph.D. Professional Seminar Homepage. 
<hr>
<h5><em>Notes by hollandm@cs.cornell.edu. </em> 
